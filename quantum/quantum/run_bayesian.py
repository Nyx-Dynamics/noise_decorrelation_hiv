#!/usr/bin/env python3
"""
Bayesian Model v3.6 - EXPANDED DATASET
Works from /quantum/ directory
Loads: quantum/data/curated/CONSOLIDATED_MRS_DATA_FOR_MODEL.csv

Extended: Can dispatch to separated pipelines with --pipeline {absolute,ratio}
If --pipeline is not provided, runs the legacy expanded individual-level model.
"""

import sys
import argparse
import numpy as np
import pandas as pd
import pymc as pm
import arviz as az
from scipy import stats
import warnings
from pathlib import Path
warnings.filterwarnings('ignore')


def _maybe_dispatch_to_pipeline(argv: list[str]) -> bool:
    """If --pipeline is provided, dispatch to the selected pipeline and return True.
    Otherwise return False to let the legacy script continue.
    """
    if "--pipeline" not in argv:
        return False

    # Minimal parser to extract the pipeline and collect remaining args
    p = argparse.ArgumentParser(add_help=False)
    p.add_argument("--pipeline", choices=["absolute", "ratio"], required=True)
    # Parse known-only to avoid interfering with downstream
    ns, remaining = p.parse_known_args(argv[1:])

    if ns.pipeline == "absolute":
        from . import pipeline_absolute as mod
        # Pass through only args relevant to absolute pipeline (it will parse its own)
        mod.main(remaining)
        return True
    elif ns.pipeline == "ratio":
        from . import pipeline_ratio as mod
        mod.main(remaining)
        return True
    return False


if _maybe_dispatch_to_pipeline(sys.argv):
    # Already handled by specific pipeline; exit early
    sys.exit(0)

print("\n" + "â•”" + "="*78 + "â•—")
print("â•‘" + " "*20 + "BAYESIAN MODEL v3.6 - EXPANDED" + " "*27 + "â•‘")
print("â•‘" + " "*15 + "Individual Patient Data: n=44 Acute HIV" + " "*24 + "â•‘")
print("â•š" + "="*78 + "â•\n")

# ============================================================================
# LOAD DATA
# ============================================================================

print("="*80)
print("LOADING DATA")
print("="*80)

# Try different possible paths
possible_paths = [
    'quantum/data/curated/CONSOLIDATED_MRS_DATA_FOR_MODEL.csv',  # From /quantum/ dir
    'data/curated/CONSOLIDATED_MRS_DATA_FOR_MODEL.csv',  # From /quantum/quantum/ dir
    './CONSOLIDATED_MRS_DATA_FOR_MODEL.csv',  # Current directory
    '/Users/acdstudpro/Documents/Github/noise_decorrelation_HIV/quantum/quantum/data/curated/CONSOLIDATED_MRS_DATA_FOR_MODEL.csv'  # Absolute
]

df_full = None
for path in possible_paths:
    try:
        print(f"Trying: {path}")
        df_full = pd.read_csv(path)
        print(f"âœ… Loaded from: {path}")
        print(f"   Records: {len(df_full)}")
        break
    except FileNotFoundError:
        continue

if df_full is None:
    print("\nâŒ Could not find data file. Please run from:")
    print("   /Users/acdstudpro/Documents/Github/noise_decorrelation_HIV/quantum/")
    print("\nOr place CONSOLIDATED_MRS_DATA_FOR_MODEL.csv in current directory")
    exit(1)

print("\nðŸ“Š Phase distribution:")
print(df_full['Phase'].value_counts())

# ============================================================================
# EXTRACT BASAL GANGLIA DATA
# ============================================================================

print("\n" + "="*80)
print("EXTRACTING BASAL GANGLIA DATA")
print("="*80)

# Get acute BG data from Valcour
acute_bg = df_full[(df_full['Phase'] == 'Acute') & 
                    (df_full['Region'] == 'BG') & 
                    (df_full['Study'] == 'Valcour_2015')].copy()

print(f"\nâœ… Found {len(acute_bg)} individual acute patients")

naa_obs_acute = acute_bg['NAA'].dropna().values
cho_obs_acute = acute_bg['Cho'].dropna().values

print(f"   NAA: n={len(naa_obs_acute)}")
print(f"   Cho: n={len(cho_obs_acute)}")

# Reference values
naa_obs_control = np.array([9.55])
cho_obs_control = np.array([2.18])
naa_obs_chronic = np.array([8.79])
cho_obs_chronic = np.array([2.40])

print(f"\nðŸ“Š ACUTE PHASE:")
print(f"   NAA = {naa_obs_acute.mean():.2f} Â± {naa_obs_acute.std():.2f} mM")
print(f"   Range: {naa_obs_acute.min():.2f} - {naa_obs_acute.max():.2f} mM")

# Stats
t_stat, p_val = stats.ttest_1samp(naa_obs_acute, naa_obs_control[0])
pct_change = ((naa_obs_acute.mean() - naa_obs_control[0])/naa_obs_control[0]*100)

print(f"\nðŸ“Š ACUTE vs CONTROL:")
print(f"   Change: +{pct_change:.1f}%")
print(f"   p-value: {p_val:.6f} ***")

# ============================================================================
# BUILD MODEL
# ============================================================================

print("\n" + "="*80)
print("BUILDING MODEL")
print("="*80)

V_max_base = 100.0
K_m = 50.0
S_0 = 100.0
V_base = V_max_base * S_0 / (K_m + S_0)
Î±_NAA = 9.55 / V_base

with pm.Model() as model:
    
    # Priors
    Î¾_acute = pm.TruncatedNormal('Î¾_acute', mu=0.6, sigma=0.1, lower=0.3, upper=0.9)
    Î¾_chronic = pm.TruncatedNormal('Î¾_chronic', mu=0.8, sigma=0.1, lower=0.5, upper=1.2)
    Î¾_control = pm.TruncatedNormal('Î¾_control', mu=0.5, sigma=0.05, lower=0.3, upper=0.7)
    
    Ïƒ_noise_acute = pm.TruncatedNormal('Ïƒ_noise_acute', mu=5.0, sigma=1.0, lower=2.0, upper=10.0)
    Ïƒ_noise_chronic = pm.TruncatedNormal('Ïƒ_noise_chronic', mu=2.0, sigma=0.5, lower=0.5, upper=4.0)
    Ïƒ_noise_control = pm.TruncatedNormal('Ïƒ_noise_control', mu=0.5, sigma=0.2, lower=0.1, upper=1.0)
    
    Î²_Î¾ = pm.TruncatedNormal('Î²_Î¾', mu=2.0, sigma=0.5, lower=1.0, upper=3.0)
    
    # Protection factors
    F_acute = pm.Deterministic('F_acute', pm.math.exp(-Î²_Î¾ * Î¾_acute))
    F_chronic = pm.Deterministic('F_chronic', pm.math.exp(-Î²_Î¾ * Î¾_chronic))
    F_control = pm.Deterministic('F_control', pm.math.exp(-Î²_Î¾ * Î¾_control))
    
    # Enzyme activity
    V_acute = pm.Deterministic('V_acute', V_base * (1 + F_acute * Ïƒ_noise_acute / 10))
    V_chronic = pm.Deterministic('V_chronic', V_base * (1 - (1-F_chronic) * Ïƒ_noise_chronic / 5))
    V_control = pm.Deterministic('V_control', V_base * (1 + F_control * Ïƒ_noise_control / 10))
    
    # NAA predictions
    NAA_acute_mean = pm.Deterministic('NAA_acute_mean', Î±_NAA * V_acute)
    NAA_chronic_mean = pm.Deterministic('NAA_chronic_mean', Î±_NAA * V_chronic)
    NAA_control_mean = pm.Deterministic('NAA_control_mean', Î±_NAA * V_control)
    
    # Cho predictions
    Cho_acute_mean = pm.Deterministic('Cho_acute_mean', 2.18 * (1 + Ïƒ_noise_acute / 20))
    Cho_chronic_mean = pm.Deterministic('Cho_chronic_mean', 2.18 * (1 + Ïƒ_noise_chronic / 15))
    Cho_control_mean = pm.Deterministic('Cho_control_mean', 2.18 * (1 + Ïƒ_noise_control / 20))
    
    # Observation noise
    Ïƒ_obs_acute = pm.HalfNormal('Ïƒ_obs_acute', sigma=1.5)
    Ïƒ_obs_chronic = pm.HalfNormal('Ïƒ_obs_chronic', sigma=1.0)
    Ïƒ_obs_control = pm.HalfNormal('Ïƒ_obs_control', sigma=0.5)
    Ïƒ_cho_acute = pm.HalfNormal('Ïƒ_cho_acute', sigma=0.5)
    
    # Likelihood
    NAA_acute_obs = pm.Normal('NAA_acute_obs', mu=NAA_acute_mean, sigma=Ïƒ_obs_acute, observed=naa_obs_acute)
    NAA_chronic_obs = pm.Normal('NAA_chronic_obs', mu=NAA_chronic_mean, sigma=Ïƒ_obs_chronic, observed=naa_obs_chronic)
    NAA_control_obs = pm.Normal('NAA_control_obs', mu=NAA_control_mean, sigma=Ïƒ_obs_control, observed=naa_obs_control)
    Cho_acute_obs = pm.Normal('Cho_acute_obs', mu=Cho_acute_mean, sigma=Ïƒ_cho_acute, observed=cho_obs_acute)
    Cho_control_obs = pm.Normal('Cho_control_obs', mu=Cho_control_mean, sigma=0.2, observed=cho_obs_control)
    
    # Hypothesis
    Î”Î¾ = pm.Deterministic('Î”Î¾', Î¾_chronic - Î¾_acute)

print("âœ… Model built!")

# ============================================================================
# SAMPLE
# ============================================================================

print("\n" + "="*80)
print("RUNNING MCMC (10-15 minutes)...")
print("="*80)

with model:
    trace = pm.sample(
        draws=2000,
        tune=1000,
        chains=4,
        cores=4,
        target_accept=0.95,
        return_inferencedata=True,
        random_seed=42
    )
    print("\nâœ… Sampling complete!")
    
    ppc = pm.sample_posterior_predictive(trace, random_seed=42)
    print("âœ… Posterior predictive complete!")

# ============================================================================
# RESULTS
# ============================================================================

print("\n" + "="*80)
print("RESULTS")
print("="*80)

posterior = trace.posterior

Î¾_acute_samples = posterior['Î¾_acute'].values.flatten()
Î¾_chronic_samples = posterior['Î¾_chronic'].values.flatten()
Î”Î¾_samples = posterior['Î”Î¾'].values.flatten()
Î²_Î¾_samples = posterior['Î²_Î¾'].values.flatten()

print("\nðŸ”¬ CORRELATION LENGTHS:")
print(f"   Î¾_acute = {Î¾_acute_samples.mean():.3f} Â± {Î¾_acute_samples.std():.3f} nm")
print(f"   Î¾_chronic = {Î¾_chronic_samples.mean():.3f} Â± {Î¾_chronic_samples.std():.3f} nm")
print(f"   Î”Î¾ = {Î”Î¾_samples.mean():.3f} Â± {Î”Î¾_samples.std():.3f} nm")

P_acute_shorter = (Î”Î¾_samples > 0).sum() / len(Î”Î¾_samples)
print(f"\nâœ… P(Î¾_acute < Î¾_chronic) = {P_acute_shorter:.4f}")

if P_acute_shorter > 0.999:
    print("   *** STRONGLY SUPPORTED ***")
elif P_acute_shorter > 0.99:
    print("   *** SUPPORTED ***")

print(f"\nðŸ”¬ PROTECTION EXPONENT:")
print(f"   Î²_Î¾ = {Î²_Î¾_samples.mean():.2f} Â± {Î²_Î¾_samples.std():.2f}")

naa_acute_pred = posterior['NAA_acute_mean'].values.flatten()
print(f"\nðŸ“Š NAA PREDICTION:")
print(f"   Predicted: {naa_acute_pred.mean():.2f} mM")
print(f"   Observed: {naa_obs_acute.mean():.2f} mM")
print(f"   Error: {abs(naa_acute_pred.mean() - naa_obs_acute.mean())/naa_obs_acute.mean()*100:.1f}%")

# ============================================================================
# SAVE
# ============================================================================

print("\n" + "="*80)
print("SAVING")
print("="*80)

Path('outputs').mkdir(exist_ok=True)

trace.to_netcdf('outputs/trace.nc')
print("âœ… outputs/trace.nc")

az.summary(trace, hdi_prob=0.95).to_csv('outputs/summary.csv')
print("âœ… outputs/summary.csv")

results = pd.DataFrame({
    'Parameter': ['Î¾_acute', 'Î¾_chronic', 'Î”Î¾', 'Î²_Î¾', 'P(hypothesis)'],
    'Mean': [Î¾_acute_samples.mean(), Î¾_chronic_samples.mean(), 
             Î”Î¾_samples.mean(), Î²_Î¾_samples.mean(), P_acute_shorter],
    'SD': [Î¾_acute_samples.std(), Î¾_chronic_samples.std(),
           Î”Î¾_samples.std(), Î²_Î¾_samples.std(), np.nan]
})
results.to_csv('outputs/results.csv', index=False)
print("âœ… outputs/results.csv")

print("\n" + "="*80)
print("COMPLETE!")
print("="*80)
print(f"\nðŸŽ¯ n={len(naa_obs_acute)} patients")
print(f"   P(Î¾_acute < Î¾_chronic) = {P_acute_shorter:.4f}")
print(f"   NAA error = {abs(naa_acute_pred.mean() - naa_obs_acute.mean())/naa_obs_acute.mean()*100:.1f}%")
print("\n" + "="*80)
